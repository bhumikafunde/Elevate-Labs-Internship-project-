{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f93e273",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Telecom Customer Churn â€” Endâ€‘toâ€‘End ML Notebook\n",
    "**Objective:** Predict churn and derive actionable retention strategies.\n",
    "\n",
    "**Tools:** Python, pandas, scikitâ€‘learn, matplotlib, (optional) SHAP / ELI5\n",
    "\n",
    "> Put your dataset path in `DATA_PATH` below. Expected format: a CSV with a binary `churn` column (1 = churned, 0 = retained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6535e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Setup ====\n",
    "import os, warnings, math, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "                             roc_curve, classification_report, confusion_matrix)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 120)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Try optional libraries quietly\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except Exception:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import eli5\n",
    "    from eli5.sklearn import PermutationImportance as ELI5PermutationImportance\n",
    "    ELI5_AVAILABLE = True\n",
    "except Exception:\n",
    "    ELI5_AVAILABLE = False\n",
    "\n",
    "print(f\"SHAP available: {SHAP_AVAILABLE}\") \n",
    "print(f\"ELI5 available: {ELI5_AVAILABLE}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2e5c8",
   "metadata": {},
   "source": [
    "## 1) Load Data\n",
    "Update `DATA_PATH` to your CSV. The CSV must include a binary target column **`churn`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Data Loading ====\n",
    "# TODO: Set your dataset path here\n",
    "DATA_PATH = 'telecom_churn.csv'  # e.g., '/path/to/telecom_churn.csv'\n",
    "\n",
    "assert os.path.exists(DATA_PATH), f\"File not found: {DATA_PATH}. Please update DATA_PATH above.\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Basic checks\n",
    "assert 'churn' in df.columns, \"Your data must contain a binary 'churn' column (1 = churned, 0 = retained).\"\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a898b",
   "metadata": {},
   "source": [
    "## 2) Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n",
    "print('Class balance (churn=1 proportion):', df['churn'].mean())\n",
    "print(df['churn'].value_counts(normalize=True))\n",
    "\n",
    "# Missing rates\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "print('Top missing columns:\\n', missing.head(20))\n",
    "\n",
    "# Simple numeric overview\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in df.columns if c not in num_cols]\n",
    "print('Numeric columns:', num_cols[:20])\n",
    "print('Categorical columns:', cat_cols[:20])\n",
    "\n",
    "# Optional: a few basic histograms (matplotlib only; no seaborn per instructions)\n",
    "for col in [c for c in num_cols if c != 'churn'][:6]:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=30)\n",
    "    plt.title(f'Distribution: {col}')\n",
    "    plt.xlabel(col); plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2a4c3",
   "metadata": {},
   "source": [
    "## 3) Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['churn'])\n",
    "y = df['churn'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "num_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = [c for c in X_train.columns if c not in num_features]\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, num_features),\n",
    "        ('cat', categorical_pipeline, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c494ee",
   "metadata": {},
   "source": [
    "## 4) Train Models (Logistic Regression, Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = Pipeline(steps=[('prep', preprocess),\n",
    "                         ('clf', LogisticRegression(max_iter=200, class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = Pipeline(steps=[('prep', preprocess),\n",
    "                    ('clf', RandomForestClassifier(\n",
    "                        n_estimators=400, max_depth=None, min_samples_split=2,\n",
    "                        class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "def evaluate(model, X_test, y_test, name='model'):\n",
    "    proba = model.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    ap = average_precision_score(y_test, proba)\n",
    "    print(f\"{name} | ROC-AUC: {auc:.4f} | PR-AUC: {ap:.4f}\")\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve'); plt.legend()\n",
    "    plt.show()\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, proba)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f\"{name} (AP={ap:.3f})\")\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve'); plt.legend()\n",
    "    plt.show()\n",
    "    return proba\n",
    "\n",
    "print(\"\\n=== Validation Metrics ===\")\n",
    "proba_lr = evaluate(log_reg, X_test, y_test, 'LogisticRegression')\n",
    "proba_rf = evaluate(rf, X_test, y_test, 'RandomForest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540450b",
   "metadata": {},
   "source": [
    "## 5) Business-Aware Threshold Tuning\n",
    "Pick a probability threshold that balances precision/recall to your goals (e.g., retention budget)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = rf  # choose the better model after reviewing metrics above\n",
    "\n",
    "proba = chosen_model.predict_proba(X_test)[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, proba)\n",
    "\n",
    "# Example: maximize F1\n",
    "f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[max(best_idx-1,0)]  # thresholds has len-1 compared to precision/recall\n",
    "print(f\"Best F1 threshold â‰ˆ {best_threshold:.3f}; Precision={precision[best_idx]:.3f}, Recall={recall[best_idx]:.3f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, f1_scores[1:], label='F1 vs Threshold')  # skip the first precision/recall point\n",
    "plt.xlabel('Threshold'); plt.ylabel('F1 score'); plt.title('Threshold Tuning'); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de792966",
   "metadata": {},
   "source": [
    "## 6) Explainability (Permutation Importance, optional SHAP/ELI5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ece451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Importance on validation set\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "def get_feature_names(preprocess, num_features, cat_features):\n",
    "    num_names = list(num_features)\n",
    "    cat_encoder = preprocess.named_transformers_['cat'].named_steps['onehot']\n",
    "    cat_names = list(cat_encoder.get_feature_names_out(cat_features)) if hasattr(cat_encoder, 'get_feature_names_out') else []\n",
    "    return num_names + cat_names\n",
    "\n",
    "# Build a clone that exposes the trained preprocess\n",
    "prep = chosen_model.named_steps['prep']\n",
    "clf = chosen_model.named_steps['clf']\n",
    "\n",
    "X_test_transformed = prep.transform(X_test)\n",
    "feature_names = get_feature_names(prep, num_features, cat_features)\n",
    "\n",
    "perm = permutation_importance(clf, X_test_transformed, y_test, n_repeats=10, random_state=RANDOM_STATE, scoring='roc_auc')\n",
    "imp = pd.DataFrame({'feature': feature_names, 'importance': perm.importances_mean}).sort_values('importance', ascending=False)\n",
    "display(imp.head(30))\n",
    "\n",
    "plt.figure()\n",
    "imp.head(20).sort_values('importance').plot(kind='barh', x='feature', y='importance', legend=False)\n",
    "plt.title('Permutation Importance (Top 20)')\n",
    "plt.xlabel('Mean importance'); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Optional: SHAP (if available)\n",
    "if SHAP_AVAILABLE:\n",
    "    try:\n",
    "        explainer = shap.Explainer(clf, X_test_transformed, feature_names=feature_names)\n",
    "        shap_values = explainer(X_test_transformed[:200])  # sample for speed\n",
    "        shap.summary_plot(shap_values, plot_type='bar', show=True)\n",
    "        shap.summary_plot(shap_values, show=True)\n",
    "    except Exception as e:\n",
    "        print('SHAP failed:', e)\n",
    "\n",
    "# Optional: ELI5 permutation importance (if available)\n",
    "if ELI5_AVAILABLE:\n",
    "    try:\n",
    "        perm_eli5 = ELI5PermutationImportance(clf, random_state=RANDOM_STATE, scoring='roc_auc').fit(X_test_transformed, y_test)\n",
    "        import eli5\n",
    "        display(eli5.show_weights(perm_eli5, feature_names=feature_names, top=20))\n",
    "    except Exception as e:\n",
    "        print('ELI5 failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fa1e3",
   "metadata": {},
   "source": [
    "## 7) Confusion Matrix at Chosen Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01367cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (proba >= best_threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f360b95",
   "metadata": {},
   "source": [
    "## 8) Score Full Dataset & Create Segments\n",
    "Segments:\n",
    "- **At Risk**: predicted probability â‰¥ threshold  \n",
    "- **Loyal**: probability < threshold and tenure/usage high (if available)  \n",
    "- **Dormant**: low engagement/usage or long inactivity (if available)\n",
    "\n",
    "Rules adjust automatically based on available columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96addae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score entire dataset\n",
    "proba_full = chosen_model.predict_proba(X)[:,1]\n",
    "scored = X.copy()\n",
    "scored['churn_prob'] = proba_full\n",
    "\n",
    "# Heuristics for engagement/recency if columns exist\n",
    "tenure_col = next((c for c in ['tenure','months_on_network','customer_age_months'] if c in scored.columns), None)\n",
    "usage_cols = [c for c in scored.columns if any(k in c for k in ['mins','minutes','call','data_mb','data_gb','sms','recharge_amt','recharge_count']) and c != 'churn_prob']\n",
    "recency_col = next((c for c in ['days_since_last_recharge','days_since_last_call','last_active_days'] if c in scored.columns), None)\n",
    "\n",
    "# Compute simple engagement score if possible\n",
    "engagement = None\n",
    "if usage_cols:\n",
    "    tmp = scored[usage_cols].copy()\n",
    "    for c in usage_cols:\n",
    "        if not np.issubdtype(tmp[c].dtype, np.number):\n",
    "            tmp[c] = pd.to_numeric(tmp[c], errors='coerce')\n",
    "    engagement = tmp.fillna(0).mean(axis=1)\n",
    "else:\n",
    "    engagement = pd.Series(np.nan, index=scored.index)\n",
    "\n",
    "# Segment rules\n",
    "def segment_row(row):\n",
    "    p = row['churn_prob']\n",
    "    high_risk = p >= best_threshold\n",
    "    low_eng = False\n",
    "    if not math.isnan(engagement.iloc[row.name]):\n",
    "        low_eng = engagement.iloc[row.name] <= np.nanpercentile(engagement, 25)\n",
    "    inactive = False\n",
    "    if recency_col is not None and pd.notna(row.get(recency_col)):\n",
    "        try:\n",
    "            inactive = float(row.get(recency_col)) >= np.nanpercentile(scored[recency_col], 75)\n",
    "        except Exception:\n",
    "            inactive = False\n",
    "\n",
    "    if high_risk:\n",
    "        return 'At Risk'\n",
    "    if inactive or low_eng:\n",
    "        return 'Dormant'\n",
    "    return 'Loyal'\n",
    "\n",
    "scored['segment'] = [segment_row(scored.iloc[i]) for i in range(scored.shape[0])]\n",
    "\n",
    "# Attach identifier if present\n",
    "id_col = next((c for c in ['customer_id','user_id','msisdn','account_id','id'] if c in df.columns), None)\n",
    "if id_col is not None:\n",
    "    scored.insert(0, id_col, df[id_col])\n",
    "\n",
    "# Save scored output\n",
    "SCORED_PATH = 'scored_customers.csv'\n",
    "scored.to_csv(SCORED_PATH, index=False)\n",
    "print(f\"Saved: {SCORED_PATH}\")\n",
    "scored.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57200894",
   "metadata": {},
   "source": [
    "## 9) Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636be0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_DIR = Path('artifacts'); ARTIFACT_DIR.mkdir(exist_ok=True)\n",
    "joblib.dump(chosen_model, ARTIFACT_DIR / 'churn_model.joblib')\n",
    "meta = {\n",
    "    'created': str(pd.Timestamp.now()),\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'best_threshold': float(best_threshold),\n",
    "    'features_numeric': num_features,\n",
    "    'features_categorical': cat_features\n",
    "}\n",
    "with open(ARTIFACT_DIR / 'metadata.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print('Artifacts saved in ./artifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd239fd",
   "metadata": {},
   "source": [
    "## 10) SQL Miniâ€‘Guide (Aggregation Examples)\n",
    "\n",
    "```sql\n",
    "-- Calls & Usage\n",
    "SELECT customer_id,\n",
    "       SUM(outgoing_call_minutes) AS total_outgoing_mins,\n",
    "       SUM(incoming_call_minutes) AS total_incoming_mins,\n",
    "       SUM(data_mb) AS data_mb_total,\n",
    "       COUNT(*) AS call_events\n",
    "FROM cdr_events\n",
    "GROUP BY customer_id;\n",
    "\n",
    "-- Complaints\n",
    "SELECT customer_id,\n",
    "       COUNT(*) AS complaints_90d\n",
    "FROM complaints\n",
    "WHERE complaint_date >= CURRENT_DATE - INTERVAL '90 day'\n",
    "GROUP BY customer_id;\n",
    "\n",
    "-- Recharge frequency & amount\n",
    "SELECT customer_id,\n",
    "       COUNT(*) FILTER (WHERE recharge_date >= CURRENT_DATE - INTERVAL '30 day') AS recharge_cnt_30d,\n",
    "       SUM(amount)  FILTER (WHERE recharge_date >= CURRENT_DATE - INTERVAL '30 day') AS recharge_amt_30d,\n",
    "       MAX(recharge_date) AS last_recharge_date\n",
    "FROM recharges\n",
    "GROUP BY customer_id;\n",
    "\n",
    "-- Join & label churn (example: no activity for 60+ days)\n",
    "WITH base AS (... your aggregates ...)\n",
    "SELECT b.*, CASE WHEN COALESCE(DATEDIFF('day', last_activity_date, CURRENT_DATE), 999) > 60 THEN 1 ELSE 0 END AS churn\n",
    "FROM base b;\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
